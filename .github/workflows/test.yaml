name: Scrape TESTING

on:
  workflow_dispatch:

jobs:
  batch_1_scrape_and_submit:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository content
        uses: actions/checkout@v4
      
      - name: Install uv (Python package manager)
        uses: astral-sh/setup-uv@v2

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          uv sync
          uv pip install -e .

      - name: Set up Google Chrome & ChromeDriver
        uses: browser-actions/setup-chrome@v1
        with:
          # installs the very latest Chrome snapshot (same as default)
          chrome-version: 'latest'
          # also installs the matching ChromeDriver binary
          install-chromedriver: true
          
      - name: Run scraping script for all news source
        run: uv run -m scraper_engine.sources.idx.scrape_financial_bisnis 1 "finan"
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          DB_KEY: ${{ secrets.DB_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          GROQ_API_KEY1: ${{ secrets.GROQ_API_KEY1 }}
          GROQ_API_KEY2: ${{ secrets.GROQ_API_KEY2 }}
          GROQ_API_KEY_DEV: ${{ secrets.GROQ_API_KEY_DEV }}
          GROQ_API_KEY3: ${{ secrets.GROQ_API_KEY3 }}
          GROQ_API_KEY4: ${{ secrets.GROQ_API_KEY4 }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          GEMINI_API_KEY2: ${{ secrets.GEMINI_API_KEY2 }}
          PROXY: ${{ secrets.PROXY }}
       
     
