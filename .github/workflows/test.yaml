name: Scrape Testing

on:
  workflow_dispatch:
    inputs:
      scraper_module:
        description: 'Select scraper to run (without .py)'
        required: true
        default: 'scrape_financial_bisnis'
        type: choice
        options:
          - scrape_abaf
          - scrape_antaranews
          - scrape_asian_telekom
          - scrape_bca_news
          - scrape_emiten_news
          - scrape_bisnis_com
          - scrape_gapki
          - scrape_icn
          - scrape_idn_business_post
          - scrape_idnfinancials
          - scrape_idnminer
          - scrape_insight_kontan
          - scrape_jakartaglobe
          - scrape_jakartapost
          - scrape_kontan
          - scrape_minerba
          - scrape_mining
          - scrape_petromindo
      page_number:
        description: 'Page number'
        required: true
        default: '1'
        type: string
      output_name:
        description: 'Output Name arg (e.g. "finan", "bca")'
        required: true
        default: 'manual_test'
        type: string

jobs:
  testing:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository content
        uses: actions/checkout@v4
      
      - name: Install uv (Python package manager)
        uses: astral-sh/setup-uv@v2

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          uv sync
          uv pip install -e .

      - name: Set up Google Chrome & ChromeDriver
        uses: browser-actions/setup-chrome@v1
        with:
          chrome-version: 'latest'
          install-chromedriver: true
          
      - name: Run Selected Scraper
        run: |
          echo "Running module: ${{ inputs.scraper_module }} on page ${{ inputs.page_number }}"
          uv run -m scraper_engine.sources.idx.${{ inputs.scraper_module }} ${{ inputs.page_number }} "${{ inputs.output_name }}"
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          DB_KEY: ${{ secrets.DB_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          GROQ_API_KEY1: ${{ secrets.GROQ_API_KEY1 }}
          GROQ_API_KEY2: ${{ secrets.GROQ_API_KEY2 }}
          GROQ_API_KEY_DEV: ${{ secrets.GROQ_API_KEY_DEV }}
          GROQ_API_KEY3: ${{ secrets.GROQ_API_KEY3 }}
          GROQ_API_KEY4: ${{ secrets.GROQ_API_KEY4 }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          GEMINI_API_KEY2: ${{ secrets.GEMINI_API_KEY2 }}
          PROXY: ${{ secrets.PROXY }}

      - name: Upload Scraper Results
        uses: actions/upload-artifact@v4
        if: always() # Upload even if the script fails (to check partial data)
        with:
          name: scrape-result-${{ inputs.output_name }}
          path: data/${{ inputs.output_name }}.*
          retention-days: 1